{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_accuracy(Y_orig, Y_pred):\n",
    "    no_classes = len(np.unique(Y_orig))\n",
    "    accuracy_dict = {}\n",
    "    accuracy_list = []\n",
    "    for label in range(no_classes):\n",
    "        numerator = 0\n",
    "        \n",
    "        for index in range(len(Y_orig)):\n",
    "            if(Y_orig[index] == Y_pred[index] and Y_pred[index] == label):\n",
    "                numerator += 1\n",
    "\n",
    "            if(Y_orig[index] != label and Y_pred[index] != label):\n",
    "                numerator += 1\n",
    "                \n",
    "                \n",
    "        accuracy_dict[label] = numerator/len(Y_orig)\n",
    "        accuracy_list.append(numerator/len(Y_orig))\n",
    "        \n",
    "    for i in accuracy_dict:\n",
    "        print(\"Class \",i,\" : \",accuracy_dict[i])\n",
    "    \n",
    "    return(np.array(accuracy_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(\"MNIST_dataset/train_set.pkl\",\"rb\"))\n",
    "test_data = pickle.load(open(\"MNIST_dataset/test_set.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_train = np.array(train_data.Image)\n",
    "Y_train = np.array(train_data.Labels)\n",
    "\n",
    "X_temp_test = np.array(test_data.Image)\n",
    "Y_test = np.array(test_data.Labels)\n",
    "\n",
    "# 784 represent 28*28\n",
    "# Since originally the data was in a image dataype\n",
    "# when we converted image type to numpy array we got a 2d array of shape (28,28)\n",
    "# since in case of logistic regression every data point should be represented by a single vector\n",
    "# the below process was carried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(X_temp_train),784))\n",
    "X_test  = np.zeros((len(X_temp_test),784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i] = np.reshape(np.array(X_temp_train[i]),[1,784])[0]\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = np.reshape(np.array(X_temp_test[i]),[1,784])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_reg(regulaiser = \"l2\"):\n",
    "    model = LogisticRegression(penalty = regulaiser,random_state=0,max_iter = 1000,multi_class= \"ovr\",C=2,solver=\"liblinear\",verbose=5)\n",
    "\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    Y_train_predict = model.predict(X_train)\n",
    "    print(\"\\n \\n ****************\")\n",
    "    print(\"Training Accuracy for each class : \"+regulaiser.upper()+\" regularization\")\n",
    "    avg_train_acc = multiclass_accuracy(Y_train,Y_train_predict)\n",
    "\n",
    "    Y_test_predict = model.predict(X_test)\n",
    "    print(\"\\n \\n ****************\")\n",
    "    print(\"Testing Accuracy for each class : \"+regulaiser.upper()+\" regularization\")\n",
    "    avg_test_acc = multiclass_accuracy(Y_test,Y_test_predict)\n",
    "\n",
    "    print(\"\\n \\n ****************\")\n",
    "    print(\"In \"+regulaiser.upper() + \" Average accuracy for\")\n",
    "    print(\"Training :\", avg_train_acc)\n",
    "    print(\"Testing  :\",avg_test_acc)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      " \n",
      " ****************\n",
      "Training Accuracy for each class : L1 regularization\n",
      "Class  0  :  0.9998\n",
      "Class  1  :  0.9999\n",
      "Class  2  :  0.9956\n",
      "Class  3  :  0.9925\n",
      "Class  4  :  0.9998\n",
      "Class  5  :  0.9941\n",
      "Class  6  :  1.0\n",
      "Class  7  :  0.9994\n",
      "Class  8  :  0.9922\n",
      "Class  9  :  0.9951\n",
      "\n",
      " \n",
      " ****************\n",
      "Testing Accuracy for each class : L1 regularization\n",
      "Class  0  :  0.985\n",
      "Class  1  :  0.9855\n",
      "Class  2  :  0.9595\n",
      "Class  3  :  0.9625\n",
      "Class  4  :  0.969\n",
      "Class  5  :  0.957\n",
      "Class  6  :  0.978\n",
      "Class  7  :  0.968\n",
      "Class  8  :  0.9485\n",
      "Class  9  :  0.959\n",
      "\n",
      " \n",
      " ****************\n",
      "In L1 Average accuracy for\n",
      "Training : 0.9968400000000001\n",
      "Testing  : 0.9671999999999998\n"
     ]
    }
   ],
   "source": [
    "l1_model = select_reg(\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      " \n",
      " ****************\n",
      "Training Accuracy for each class : L2 regularization\n",
      "Class  0  :  0.9998\n",
      "Class  1  :  1.0\n",
      "Class  2  :  0.9954\n",
      "Class  3  :  0.9924\n",
      "Class  4  :  0.9999\n",
      "Class  5  :  0.9943\n",
      "Class  6  :  1.0\n",
      "Class  7  :  0.9998\n",
      "Class  8  :  0.9926\n",
      "Class  9  :  0.9956\n",
      "\n",
      " \n",
      " ****************\n",
      "Testing Accuracy for each class : L2 regularization\n",
      "Class  0  :  0.984\n",
      "Class  1  :  0.9855\n",
      "Class  2  :  0.961\n",
      "Class  3  :  0.9595\n",
      "Class  4  :  0.9665\n",
      "Class  5  :  0.957\n",
      "Class  6  :  0.9755\n",
      "Class  7  :  0.965\n",
      "Class  8  :  0.9465\n",
      "Class  9  :  0.9555\n",
      "\n",
      " \n",
      " ****************\n",
      "In L2 Average accuracy for\n",
      "Training : 0.99698\n",
      "Testing  : 0.9656\n"
     ]
    }
   ],
   "source": [
    "l2_model = select_reg(\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
